<div align="center">

# ğŸï¸ PitStop AI

### _AI-Powered Race Strategy Agent_

[![Next.js](https://img.shields.io/badge/Next.js-black?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://docker.com/)

**Powered by** [Meta Llama](https://ai.meta.com/llama/) â€¢ [Cerebras](https://cerebras.net/) â€¢ [Docker](https://docker.com/)

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“– Documentation](#-agentic-workflow) â€¢ [ğŸ¯ Demo](#-demo-guide) â€¢ [ğŸ† Features](#-why-this-matters)

---

</div>

## ğŸ¯ What is PitStop AI?

**PitStop AI** is an autonomous race strategy agent that uses **iterative AI planning** to recommend optimal pit stop strategies. Ask in plain Englishâ€”the agent parses your race state, generates candidates, simulates outcomes, analyzes results, and refines until convergence.

### âš¡ TL;DR

```
You: "We're 0.5s ahead at lap 8. Pit lap 12 for hards or lap 10 for mediums?"
                                  â†“
        ğŸ§  AI Agent parses â†’ generates strategies â†’ simulates
                                  â†“
        ğŸ“Š Iterates 2-3 times, converges to optimal solution
                                  â†“
        âœ¨ Result: "Pit lap 12 (hard) â†’ +1.24s ahead by lap 18"
```

---

## ğŸ† Why This Matters

| Feature                       | Description                                                                        |
| ----------------------------- | ---------------------------------------------------------------------------------- |
| ğŸ¤– **True Agentic AI**        | Multi-stage workflow: Parse â†’ Plan â†’ Simulate â†’ Analyze â†’ Refine â†’ Converge        |
| ğŸ” **Full Transparency**      | See the agent's thinking: iterations, token usage, timings, tool arguments         |
| ğŸ“Š **Monte Carlo Simulation** | Stochastic lap times, tire degradation, pit loss with P10/P50/P90 confidence bands |
| ğŸ¨ **Accessible UX**          | No F1 knowledge requiredâ€”clear visuals and explanations for everyone               |
| âš¡ **Powered by Cerebras**    | Fast inference with Meta Llama models via OpenAI-compatible tools API              |
| ğŸ³ **One-Command Deploy**     | `docker compose up` and you're racing in 2 minutes                                 |

---

## ğŸš€ Quick Start

### Prerequisites

- ğŸ³ Docker & Docker Compose
- ğŸ”‘ (Optional) Cerebras API key for full agent mode

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/sujal-2301/PitStop-AI.git
cd PitStop-AI

# 2. (Optional) Create .env file
cp .env.example .env
# Add your LLM_API_KEY to .env

# 3. Launch with Docker Compose
docker compose up --build
```

### Access Points

| Service             | URL                                                            | Description                               |
| ------------------- | -------------------------------------------------------------- | ----------------------------------------- |
| ğŸ¨ **Frontend**     | [http://localhost:3000](http://localhost:3000)                 | Main UI with agent thinking visualization |
| ğŸ”§ **API**          | [http://localhost:8000](http://localhost:8000)                 | FastAPI backend                           |
| âœ… **Health Check** | [http://localhost:8000/healthz](http://localhost:8000/healthz) | API status                                |

> **âš¡ Pro Tip:** Works in mock mode without API keyâ€”full simulation, deterministic explanations!

---

## âš™ï¸ Configuration

Create a `.env` file in the project root:

```bash
# Frontend
FRONTEND_ORIGIN=http://localhost:3000

# LLM Configuration (Cerebras)
LLM_API_BASE=https://api.cerebras.ai/v1
LLM_API_KEY=your_cerebras_api_key_here

# Model Selection
LLM_MODEL_PLANNER=llama-4-scout-17b-16e-instruct
LLM_MODEL_EXPLAINER=llama-4-maverick-17b-128e-instruct

# Simulation API
SIM_API_URL=http://127.0.0.1:8000/run_sim
```

---

## ğŸ¯ Demo Guide

### 3-Minute Walkthrough for Judges

```markdown
1. ğŸ“ Input Query
   Type: "We're 0.5s ahead at lap 8. Pit lap 12 for hards or lap 10 for mediums?"

2. ğŸ§  Watch the Agent Think
   â”œâ”€ Parsed Constraints (lap, gap, tire state, objective)
   â”œâ”€ Iteration 1: Generated 3 strategies â†’ simulated â†’ analyzed
   â”œâ”€ Iteration 2: Refined 2 strategies â†’ simulated â†’ analyzed
   â””â”€ Converged (top strategies within 0.1s threshold)

3. âœ¨ See the Results
   â”œâ”€ Agent Thinking Panel (iterations, tokens: ~1,250, time: ~3.5s)
   â”œâ”€ Recommendation: "Pit lap 12 (hard) â†’ +1.24s ahead"
   â”œâ”€ Strategy Comparison (visual cards with progress bars)
   â””â”€ (Optional) Detailed chart with P10/P50/P90 confidence bands

4. ğŸš¨ Try Safety Car Mode
   Use preset "âš¡ Safety Car Opportunity" to see reduced pit loss modeling
```

---

## ğŸ¤– Agentic Workflow

<div align="center">

```mermaid
graph TD
    A[User Query] -->|Natural Language| B[ğŸ§  Parse Constraints]
    B -->|Structured Race State| C[ğŸ¯ Generate Candidates]
    C -->|2-4 Strategies| D[ğŸ² Simulate - Monte Carlo]
    D -->|Results P10/P50/P90| E[ğŸ“Š Analyze & Refine]
    E -->|Converged?| F{Decision}
    F -->|No - Refine| C
    F -->|Yes - Done| G[âœ¨ Best Strategy + Trace]

    style A fill:#e1f5ff
    style B fill:#fff4e6
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fff3e0
    style F fill:#ffebee
    style G fill:#e8eaf6
```

</div>

### ğŸ”„ Multi-Stage Process

| Stage           | Actor                 | Description                                                    | Output                |
| --------------- | --------------------- | -------------------------------------------------------------- | --------------------- |
| 1ï¸âƒ£ **Parse**    | ğŸ§  LLM (Planner)      | Extracts lap, gap, tire compound/age, objectives, constraints  | Structured race state |
| 2ï¸âƒ£ **Generate** | ğŸ§  LLM (Planner)      | Proposes 2-4 strategies (undercut/overcut, soft/medium/hard)   | Candidate list        |
| 3ï¸âƒ£ **Simulate** | ğŸ² Monte Carlo Engine | Stochastic lap times, degradation, pit loss (400 samples)      | P10/P50/P90 gaps      |
| 4ï¸âƒ£ **Analyze**  | ğŸ§  LLM (Planner)      | Evaluates results, proposes refinements or stops               | Continue/Converge     |
| 5ï¸âƒ£ **Refine**   | ğŸ”„ Loop               | Generates new variations, goes back to step 3                  | New candidates        |
| 6ï¸âƒ£ **Converge** | âœ… Threshold          | Stops at max iterations (3) or when top strategies within 0.1s | Final recommendation  |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js UI    â”‚ â† User inputs query in plain English
â”‚  (Port 3000)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /plan_and_explain
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI API   â”‚ â† Orchestrates agent workflow
â”‚  (Port 8000)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ ğŸ§  Iterative Planner (LLM via Cerebras)
         â”‚    â”œâ”€ Parse Constraints
         â”‚    â”œâ”€ Generate Candidates
         â”‚    â”œâ”€ Analyze & Refine
         â”‚    â””â”€ Loop until convergence
         â”‚
         â””â”€â†’ ğŸ² Monte Carlo Simulator (sim/core.py)
              â”œâ”€ Stochastic lap times
              â”œâ”€ Tire degradation curves
              â”œâ”€ Pit loss sampling
              â””â”€ Safety Car modeling
```

---

## ğŸ“ Project Structure

```
PitStop-AI/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py              # FastAPI app, endpoints, CORS, health, caching
â”‚   â”œâ”€â”€ schemas.py           # Pydantic request/response models
â”‚   â”œâ”€â”€ Dockerfile           # API container definition
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ iterative_planner.py # ğŸ§  Core agent (parse â†’ generate â†’ refine)
â”‚   â”œâ”€â”€ explainer.py         # Explanation generation
â”‚   â”œâ”€â”€ llm_client.py        # Cerebras API client
â”‚   â””â”€â”€ config.py            # LLM configuration
â”œâ”€â”€ sim/
â”‚   â””â”€â”€ core.py              # ğŸ² Monte Carlo simulation engine
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ index.js         # Main Next.js page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ AgentThinking.js # Agent trace visualization
â”‚   â”‚   â”œâ”€â”€ ComparePanel.js  # Strategy comparison
â”‚   â”‚   â”œâ”€â”€ Plot.js          # Gap evolution chart
â”‚   â”‚   â””â”€â”€ ExplainerCard.js # AI recommendation
â”‚   â”œâ”€â”€ Dockerfile           # Frontend container
â”‚   â””â”€â”€ package.json         # Node dependencies
â”œâ”€â”€ data/
â”‚   â””â”€â”€ synth_race.csv       # Synthetic race data
â””â”€â”€ docker-compose.yml       # Multi-service orchestration
```

---

## ğŸ”Œ API Reference

### Endpoints

| Method | Endpoint            | Description                | Response                                                       |
| ------ | ------------------- | -------------------------- | -------------------------------------------------------------- |
| `GET`  | `/healthz`          | Health check               | `{ status: "ok", data_loaded: true }`                          |
| `POST` | `/run_sim`          | Run Monte Carlo simulation | Simulation results with P10/P50/P90                            |
| `POST` | `/plan_and_explain` | Full agent workflow        | `{ tool_args, sim_result, trace, explanation, timings, meta }` |

### Example Response

```json
{
  "tool_args": { "base_lap": 8, "base_target_gap_s": 0.5, ... },
  "sim_result": { "candidates": [...], "base_lap": 8, ... },
  "trace": {
    "thinking_steps": ["ğŸ§  Parsing...", "âœ… Constraints: {...}", ...],
    "iterations": [{ "iteration": 1, "candidates": [...], "results": [...] }],
    "total_tokens": 1250,
    "total_simulations": 5
  },
  "explanation": { "decision": "Pit lap 12 (hard)", "rationale": [...] },
  "timings": { "planner_s": 3.45, "explainer_s": 0.82, "total_s": 4.27 },
  "meta": { "provider": "Cerebras", "planner_model": "llama-4-scout-..." }
}
```

---

## ğŸ² Simulation Features

### Monte Carlo Modeling

- **Stochastic Lap Times**: Gaussian noise per lap (configurable std dev)
- **Tire Degradation**: Compound-specific curves (soft/medium/hard)
  - Soft: 12 laps baseline, +0.12s/lap degradation
  - Medium: 18 laps baseline, +0.10s/lap degradation
  - Hard: 22 laps baseline, +0.08s/lap degradation
- **Pit Loss**: Sampled from N(21.0s, 0.5s) distribution
- **Confidence Bands**: P10/P50/P90 percentiles (10th, 50th, 90th)
- **Breakeven Lap**: First lap where gap returns to pre-pit level

### ğŸš¨ Safety Car Support

| Parameter            | Type                     | Description                   | Default            |
| -------------------- | ------------------------ | ----------------------------- | ------------------ |
| `sc_window`          | `{ start_lap, end_lap }` | Laps when SC is active        | `null`             |
| `sc_pit_loss_factor` | `float`                  | Pit loss multiplier during SC | `0.6` (40% faster) |

**Example**: SC from lap 11-13 â†’ pitting on lap 12 has 60% normal pit loss (~12.6s vs ~21s)

---

## âš¡ Performance & Reliability

| Feature                  | Implementation                          | Benefit                              |
| ------------------------ | --------------------------------------- | ------------------------------------ |
| ğŸ—‚ï¸ **LRU Cache**         | `@lru_cache(maxsize=512)` on simulation | Avoid recomputing identical requests |
| ğŸ“Š **Data Preload**      | CSV loaded once on startup              | No per-request file I/O              |
| ğŸ¥ **Health Checks**     | Docker healthchecks with `curl`         | Robust service orchestration         |
| â±ï¸ **Timing Metrics**    | Planner/explainer/total exposed         | Transparency and debugging           |
| ğŸ”„ **Convergence Logic** | Max 3 iterations or 0.1s threshold      | Efficient exploration                |

---

## ğŸ–ï¸ Sponsor Alignment

<div align="center">

| Sponsor           | Integration                                                              | Impact                                                |
| ----------------- | ------------------------------------------------------------------------ | ----------------------------------------------------- |
| **ğŸ¦™ Meta Llama** | `llama-4-scout-17b-16e-instruct`<br>`llama-4-maverick-17b-128e-instruct` | Powers all agent reasoning (parse, generate, analyze) |
| **âš¡ Cerebras**   | OpenAI-compatible tools API<br>`https://api.cerebras.ai/v1`              | Fast inference for iterative planning loops           |
| **ğŸ³ Docker**     | Multi-service compose<br>Health checks, isolated builds                  | One-command deployment, production-ready              |

</div>

---

## ğŸ§ª Testing Locally

### Step-by-Step

1. **Open** â†’ [http://localhost:3000](http://localhost:3000)
2. **Click** â†’ ğŸ† "Extend Lead Strategy" preset
3. **Watch** â†’ Agent Thinking panel unfolds:
   - Parsed constraints
   - Iteration 1: 3 strategies tested
   - Iteration 2: 2 refined strategies
   - Converged at 0.08s delta
4. **Review** â†’ Final recommendation and comparison cards
5. **Explore** â†’ Try Safety Car preset to see SC modeling

---

## ğŸ› ï¸ Troubleshooting

| Issue                            | Solution                                                           |
| -------------------------------- | ------------------------------------------------------------------ |
| âŒ "Agent modules not available" | Ensure containers built: `docker compose up --build`               |
| ğŸ”‘ "No LLM key â†’ mock mode"      | Set `LLM_API_KEY` in `.env` for full agent; mock works without key |
| ğŸŒ CORS errors                   | Check `FRONTEND_ORIGIN` matches your frontend URL                  |
| ğŸ”Œ Port conflicts                | Stop services on 3000/8000 or change ports in `docker-compose.yml` |
| ğŸ¢ Slow simulation               | Reduce `mc_samples` (default 400) or check CPU allocation          |

---

## ğŸ—ºï¸ Roadmap

### Future Enhancements

- [ ] **Clarifying Questions**: Ask user for missing info when inputs are ambiguous
- [ ] **Session Memory**: Remember user preferences and past strategies
- [ ] **Multi-Agent Roles**: Separate Strategist/Analyst/Risk agents with traceable outputs
- [ ] **Streaming Trace**: Real-time agent thinking updates via WebSocket
- [ ] **Advanced SC Logic**: Model VSC (virtual SC) and VSC delta
- [ ] **Historical Data**: Train degradation models on real race telemetry

---

## ğŸ“œ License

**Â© 2025 PitStop AI**  
Created for hackathon demonstration and judging purposes.

---

## ğŸ™ Acknowledgements

Built with â¤ï¸ using:

- **[Meta Llama](https://ai.meta.com/llama/)** - Powering agentic reasoning
- **[Cerebras](https://cerebras.net/)** - Lightning-fast inference
- **[Docker](https://docker.com/)** - Seamless orchestration
- **[FastAPI](https://fastapi.tiangolo.com/)** - High-performance API framework
- **[Next.js](https://nextjs.org/)** - Modern React framework
- **[Chart.js](https://chartjs.org/)** - Beautiful data visualization

---

<div align="center">

### ğŸï¸ Ready to optimize your race strategy?

**[Get Started Now](#-quick-start)** | **[View Demo](#-demo-guide)** | **[Read Docs](#-agentic-workflow)**

Made with ğŸ by [Sujal](https://github.com/sujal-2301)

</div>
